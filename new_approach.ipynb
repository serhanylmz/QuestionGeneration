{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Dataset Generation: SQuAD + Trivia QA + Hotpot QA + Natural Questions QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "def process_squad(dataset: Any) -> List[Dict[str, str]]:\n",
    "    return [\n",
    "        {\n",
    "            \"context\": example['context'],\n",
    "            \"question\": example['question'],\n",
    "            \"answer\": example['answers']['text'][0] if example['answers']['text'] else \"\"\n",
    "        }\n",
    "        for example in dataset['train']\n",
    "    ]\n",
    "\n",
    "def process_trivia_qa(dataset: Any) -> List[Dict[str, str]]:\n",
    "    return [\n",
    "        {\n",
    "            \"context\": example['entity_pages']['wiki_context'][0] if example['entity_pages']['wiki_context'] else \"\",\n",
    "            \"question\": example['question'],\n",
    "            \"answer\": example['answer']['value']\n",
    "        }\n",
    "        for example in dataset['train']\n",
    "        if example['entity_pages']['wiki_context']\n",
    "    ]\n",
    "\n",
    "def process_hotpot_qa(dataset: Any) -> List[Dict[str, str]]:\n",
    "    processed_data = []\n",
    "    for example in dataset['train']:\n",
    "        context = \"\"\n",
    "        for title, sentences in example['context']:\n",
    "            context += f\"{title}: {' '.join(sentences)} \"\n",
    "        processed_data.append({\n",
    "            \"context\": context.strip(),\n",
    "            \"question\": example['question'],\n",
    "            \"answer\": example['answer']\n",
    "        })\n",
    "    return processed_data\n",
    "\n",
    "def load_datasets():\n",
    "    print(\"Loading datasets...\")\n",
    "    datasets = {\n",
    "        \"SQuAD\": load_dataset(\"squad\"),\n",
    "        \"TriviaQA\": load_dataset(\"trivia_qa\", \"unfiltered\"),\n",
    "        \"HotpotQA\": load_dataset(\"hotpot_qa\", \"distractor\", trust_remote_code=True)\n",
    "    }\n",
    "    print(\"Datasets loaded successfully.\")\n",
    "    return datasets\n",
    "\n",
    "def process_datasets(datasets):\n",
    "    print(\"Processing datasets...\")\n",
    "    merged_data = []\n",
    "\n",
    "    print(\"Processing SQuAD...\")\n",
    "    merged_data.extend(process_squad(datasets[\"SQuAD\"]))\n",
    "    print(\"Processing TriviaQA...\")\n",
    "    merged_data.extend(process_trivia_qa(datasets[\"TriviaQA\"]))\n",
    "    print(\"Processing HotpotQA...\")\n",
    "    merged_data.extend(process_hotpot_qa(datasets[\"HotpotQA\"]))\n",
    "\n",
    "    # Convert to DataFrame for easy handling\n",
    "    df = pd.DataFrame(merged_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cc84d2eaf149148ef23b10f862284e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61707bf3e07b4b3a9abb3cd98556ca15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e917311649c40cbb66507be091ffa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQuAD Sample:\n",
      "Example 1:\n",
      "id\n",
      "\n",
      "Example 2:\n",
      "title\n",
      "\n",
      "Example 3:\n",
      "context\n",
      "\n",
      "Example 4:\n",
      "question\n",
      "\n",
      "Example 5:\n",
      "answers\n",
      "\n",
      "\n",
      "TriviaQA Sample:\n",
      "Example 1:\n",
      "question\n",
      "\n",
      "Example 2:\n",
      "question_id\n",
      "\n",
      "Example 3:\n",
      "question_source\n",
      "\n",
      "Example 4:\n",
      "entity_pages\n",
      "\n",
      "Example 5:\n",
      "search_results\n",
      "\n",
      "Example 6:\n",
      "answer\n",
      "\n",
      "\n",
      "HotpotQA Sample:\n",
      "Example 1:\n",
      "id\n",
      "\n",
      "Example 2:\n",
      "question\n",
      "\n",
      "Example 3:\n",
      "answer\n",
      "\n",
      "Example 4:\n",
      "type\n",
      "\n",
      "Example 5:\n",
      "level\n",
      "\n",
      "Example 6:\n",
      "supporting_facts\n",
      "\n",
      "Example 7:\n",
      "context\n",
      "\n",
      "Datasets: SQuAD, TriviaQA, HotpotQA loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "loaded_datasets = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing datasets...\n",
      "Processing SQuAD...\n",
      "Processing SQuAD...\n",
      "Processing TriviaQA...\n",
      "Processing TriviaQA...\n",
      "Processing HotpotQA...\n",
      "Processing HotpotQA...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_datasets\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 83\u001b[0m, in \u001b[0;36mprocess_datasets\u001b[1;34m(datasets)\u001b[0m\n\u001b[0;32m     81\u001b[0m merged_data\u001b[38;5;241m.\u001b[39mextend(process_trivia_qa(datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTriviaQA\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing HotpotQA...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 83\u001b[0m merged_data\u001b[38;5;241m.\u001b[39mextend(\u001b[43mprocess_hotpot_qa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHotpotQA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame for easy handling\u001b[39;00m\n\u001b[0;32m     86\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(merged_data)\n",
      "Cell \u001b[1;32mIn[8], line 45\u001b[0m, in \u001b[0;36mprocess_hotpot_qa\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     44\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m title, sentences \u001b[38;5;129;01min\u001b[39;00m example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     46\u001b[0m         context \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sentences)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m     processed_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39mstrip(),\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     51\u001b[0m     })\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "squad_df = pd.DataFrame(loaded_datasets[\"SQuAD\"][\"train\"])\n",
    "print(\"SQuAD Dataset:\")\n",
    "print(squad_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_qa_df = pd.DataFrame(loaded_datasets[\"TriviaQA\"][\"train\"])\n",
    "print(\"TriviaQA Dataset:\")\n",
    "print(trivia_qa_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpot_qa_df = pd.DataFrame(loaded_datasets[\"HotpotQA\"][\"train\"])\n",
    "print(\"HotpotQA Dataset:\")\n",
    "print(hotpot_qa_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the datasets\n",
    "merged_dataset = process_datasets(loaded_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the merged dataset\n",
    "print(\"Merged Dataset:\")\n",
    "print(merged_dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
